{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acecc187-37ab-4a73-a306-6803c3e12ae6",
   "metadata": {},
   "source": [
    "# Gemini API Masterclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eca7b946-bb5f-4bc8-a425-7249cd56b04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Gemini API key:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from google import genai\n",
    "\n",
    "# Securely prompt for the API key\n",
    "if \"GEMINI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GEMINI_API_KEY\"] = getpass.getpass(\"Enter your Gemini API key: \")\n",
    "\n",
    "# Initialize the client\n",
    "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541df2c2-58e7-4bbe-a232-d69e24d2929e",
   "metadata": {},
   "source": [
    "## Basic Text Generation\n",
    "This is the \"Hello World\" of Gemini. We'll use the Gemini 2.0 Flash model, which is the current standard for speed and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8949225c-a3b2-4f7e-9c14-6355a9d833c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini's Response:\n",
      "--------------------\n",
      "Okay, let's bake an LLM! Imagine you want to create a delicious cake. An LLM is like a *super-powered, recipe-generating baker* that can come up with variations and continuations of cake recipes based on what it's already seen.\n",
      "\n",
      "Here's the breakdown:\n",
      "\n",
      "**1. The Data: The Cookbook (Training Data)**\n",
      "\n",
      "*   **What it is:**  The core of an LLM is a massive dataset of text. Think of this as a **giant cookbook filled with countless cake recipes.** These recipes range from simple sponge cakes to elaborate wedding cakes. They include ingredients, instructions, reviews, and even stories about cake baking.\n",
      "*   **Analogy:** The more diverse and well-written the recipes in your cookbook, the better your LLM baker will learn. You need recipes in different styles, with varying levels of detail, and covering a wide range of cake types.\n",
      "\n",
      "**2. Tokenization: Breaking Down the Ingredients & Instructions (Tokenizing)**\n",
      "\n",
      "*   **What it is:** Before the baker can use the cookbook, they need to break down each recipe into individual pieces. LLMs do this with *tokenization*.  Words, parts of words, or even punctuation marks are turned into unique numerical tokens.\n",
      "*   **Analogy:** Imagine you are meticulously separating all the ingredients listed and writing them on separate sticky notes. Also, you're breaking down the steps into very simple instructions: \"Combine flour and sugar,\" \"Add butter,\" \"Bake at 350 degrees,\" etc. Each sticky note is now a token.\n",
      "\n",
      "**3. The Model Architecture: The Mixing & Baking Equipment (Neural Network)**\n",
      "\n",
      "*   **What it is:** The LLM's architecture (usually a transformer neural network) is like the **baker's kitchen**, equipped with all the necessary tools and machinery. This includes things like:\n",
      "    *   **Ovens (layers of neural network):** These process the tokens and learn the relationships between them. Each layer is a new stage of baking\n",
      "    *   **Mixers (attention mechanisms):**  These are used to focus on the most important parts of a recipe when predicting the next ingredient or instruction.  If the recipe calls for \"cream cheese frosting,\" the mixer will pay special attention to the ingredients and instructions that usually appear with cream cheese.\n",
      "    *   **Measuring cups (weights and biases):** These ensure the correct proportions and relationships between ingredients and instructions.\n",
      "*   **Analogy:** A good kitchen with the right equipment is essential for creating a great cake. The neural network layers in the LLM help the model understand complex relationships in the text.\n",
      "\n",
      "**4. Training: Learning to Bake (Model Training)**\n",
      "\n",
      "*   **What it is:** This is where the LLM actually *learns* to bake (generate text). It works by trying to predict the next token in a sequence, based on the tokens it has already seen. This is also called \"next-token prediction.\"  For instance, the model might see \"Ingredients: Flour, Sugar, Eggs...\" and try to predict the next token, which might be \"Butter.\" The model is rewarded (adjusted) when it predicts correctly and penalized (adjusted differently) when it's wrong.\n",
      "*   **Analogy:** Think of the baker initially making a lot of mistakes. They might accidentally add salt instead of sugar, or overbake the cake. Each time they mess up, they get feedback and adjust their approach – maybe they learn to read the recipe more carefully, or to pay closer attention to the oven temperature. Over time, they become a more skilled baker by learning from their mistakes.\n",
      "\n",
      "**5. Inference: Baking a New Cake (Generating Text)**\n",
      "\n",
      "*   **What it is:** Once the model is trained, you can give it a prompt (a starting point), and it will generate text that continues the pattern. For example, you might give it the prompt \"Chocolate cake with...\" and the LLM will generate the rest of the recipe, based on what it has learned from its cookbook.\n",
      "*   **Analogy:** You give the baker a partial request: \"I want a chocolate cake with...\" The trained baker now uses their knowledge to suggest ingredients, baking instructions, and even decorations, based on the vast library of recipes they've already learned.\n",
      "\n",
      "**6. Evaluation: Tasting the Cake (Evaluating the Output)**\n",
      "\n",
      "*   **What it is:**  We need to see if the cake the LLM baked is good. This involves analyzing the generated text for coherence, relevance, accuracy, and overall quality.\n",
      "*   **Analogy:**  We taste the cake, check its texture, and make sure it looks and tastes delicious. If the cake is dry, bland, or doesn't resemble a chocolate cake at all, we know the LLM baker needs more training or a better cookbook.\n",
      "\n",
      "**In short:**\n",
      "\n",
      "*   **Training Data (Cookbook):** Provides the knowledge and examples.\n",
      "*   **Tokenization (Ingredients/Instructions on Sticky Notes):** Breaks down the data into manageable pieces.\n",
      "*   **Model Architecture (Kitchen Equipment):**  Provides the structure for learning and processing.\n",
      "*   **Training (Learning to Bake):** Teaches the model to generate text.\n",
      "*   **Inference (Baking a New Cake):**  Generates new text based on a prompt.\n",
      "\n",
      "So, the next time you're using an LLM, think of it as a diligent, recipe-memorizing baker, skillfully crafting new textual treats based on the vast cookbook of information it has absorbed! Just remember, even the best bakers occasionally need a little human guidance to ensure the final product is truly delicious.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    contents=\"Explain how an LLM works using a baking analogy.\"\n",
    ")\n",
    "\n",
    "print(f\"Gemini's Response:\\n{'-'*20}\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8398087e-0738-4477-ac79-ee24b4d2c1cf",
   "metadata": {},
   "source": [
    "## Multimodal Capabilities (Images)\n",
    "Gemini is natively multimodal. You can show the audience how to \"see\" an image by passing a URL or a local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91e04504-0b37-4973-bfe1-f272cffb7c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://storage.googleapis.com/generativeai-downloads/images/composition.png\" width=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a description of the image and identification of the main objects:\n",
      "\n",
      "**Description:**\n",
      "\n",
      "The image appears to be a still life or a staged composition. It features a selection of everyday objects arranged on what looks like a simple surface, possibly a table. The lighting is soft and diffused, creating a gentle, almost painterly aesthetic. There's a sense of quiet contemplation and the deliberate arrangement of the items suggests a focus on form, texture, and the relationships between them.\n",
      "\n",
      "**Main Objects:**\n",
      "\n",
      "*   **Earthenware objects:** An earthenware vase, possibly terracotta in color, that could be the focal point of the arrangement.\n",
      "*   **Fruits:** A ripe pear or peach, its rounded form providing a contrast to the angular lines of other objects.\n",
      "\n",
      "This composition of simple and natural forms suggests that the artist or photographer is interested in the beauty of the mundane and the visual harmony that can be found in everyday life.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Example: Analyzing an image from a URL\n",
    "image_url = \"https://storage.googleapis.com/generativeai-downloads/images/composition.png\"\n",
    "display(Image(url=image_url, width=400))\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[\n",
    "        \"Describe what is happening in this image and identify the main objects.\",\n",
    "        image_url # The SDK handles the URL directly!\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebb9068-31d7-45f0-b3cc-517c816af09e",
   "metadata": {},
   "source": [
    "## Setting a \"System Persona\"\n",
    "System instructions allow you to define the model's behavior, tone, and constraints throughout the entire interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcf0961c-2ba6-49b1-8c39-25e72f9353d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`RecursionError` in Python signals that a recursive function has exceeded the maximum recursion depth. Debug by:\n",
      "\n",
      "1.  **Base Case:** Ensure your recursive function has a well-defined base case to terminate recursion.\n",
      "2.  **Progress:** Verify that each recursive call moves closer to the base case. Missing or incorrect progress can lead to infinite recursion.\n",
      "3.  **Tail Call Optimization:** Python lacks TCO; refactor to iterative solutions where feasible.\n",
      "4.  **Increase Recursion Limit (Caution):** `sys.setrecursionlimit(limit)` can increase the limit, but this masks underlying issues and can cause stack overflow.\n",
      "\n",
      "Example:\n",
      "\n",
      "```python\n",
      "import sys\n",
      "\n",
      "def recursive_function(n):\n",
      "    if n == 0:  # Base case\n",
      "        return 0\n",
      "    else:\n",
      "        return n + recursive_function(n - 1)  # Progress towards base case\n",
      "\n",
      "# sys.setrecursionlimit(1500) # use with caution\n",
      "print(recursive_function(100))\n",
      "```\n",
      "\n",
      "If the root cause is complex data structures (e.g., deeply nested trees), consider restructuring the data or using iterative algorithms with explicit stacks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# Define the \"rules\" for the AI\n",
    "sys_instruct = \"You are a grumpy but helpful Senior Python Architect. Keep answers concise and use technical jargon.\"\n",
    "\n",
    "# Pass the instruction into the config\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"How do I fix a RecursionError?\",\n",
    "    config=types.GenerateContentConfig(system_instruction=sys_instruct)\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237f05e1-8890-41e6-82f1-8311231a2c9a",
   "metadata": {},
   "source": [
    "## Multi-turn Chat (Stateful)\n",
    "In a standard API call, the model doesn't \"remember\" previous messages. Using chats.create handles the history for you automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac59a6e0-a14d-4969-bb51-bc709145b7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini: That's awesome! Building a robot is a fantastic project. Tell me more about Sparky! I'm excited to hear about it. To help me understand and offer helpful advice, could you tell me about:\n",
      "\n",
      "*   **What is Sparky supposed to do?** (What is its purpose? Is it for fun, a specific task, learning, etc.?)\n",
      "*   **What are its main features?** (e.g., wheels, arms, sensors, etc.)\n",
      "*   **What platform are you using?** (e.g., Arduino, Raspberry Pi, custom circuit, etc.)\n",
      "*   **What programming language are you using?** (e.g., Python, C++, etc.)\n",
      "*   **What is your current skill level in robotics?** (Beginner, intermediate, advanced)\n",
      "*   **What challenges are you facing right now?** (If any)\n",
      "*   **What are your goals for Sparky?** (short-term and long-term)\n",
      "\n",
      "The more details you provide, the better I can assist you. Good luck with Sparky!\n",
      "\n",
      "\n",
      "Gemini: A great first task for a robot like Sparky should be something simple, achievable, and that allows you to test core functionalities. Here are a few suggestions, ranging in complexity, keeping in mind that you're in the early stages:\n",
      "\n",
      "**Easiest Options (Focus on Basic Movement and Control):**\n",
      "\n",
      "1.  **\"Move in a Straight Line\":**\n",
      "    *   **Goal:** Program Sparky to move forward in a straight line for a specified distance (e.g., 1 meter) and then stop.\n",
      "    *   **Why it's good:** Tests basic motor control, potentially using encoders if available, and introduces the concept of timing or distance estimation. It helps verify your robot's wheel setup and ensures it moves in a somewhat predictable manner.\n",
      "    *   **Potential Challenges:** Uneven floor surfaces, slight differences in motor speeds that cause deviation, encoder accuracy (if using).\n",
      "\n",
      "2.  **\"Simple Obstacle Avoidance (Bump and Turn)\":**\n",
      "    *   **Goal:** Equip Sparky with a bumper switch or contact sensor at the front. Program it to move forward until it hits an obstacle, then stop, back up slightly, turn a predefined angle (e.g., 90 degrees), and continue moving forward.\n",
      "    *   **Why it's good:** Introduces a basic sensor and decision-making. Simple logic and no complex sensor data analysis are needed.\n",
      "    *   **Potential Challenges:** Reliable mounting and wiring of the bumper sensor, consistent turning angles.\n",
      "\n",
      "**Slightly More Complex (Adds Simple Sensing):**\n",
      "\n",
      "3.  **\"Line Following (Simplest Version)\":**\n",
      "    *   **Goal:** Create a simple line (e.g., black electrical tape on a white floor). Equip Sparky with a single line sensor (e.g., an infrared sensor). Program it to follow the line by adjusting its motor speeds based on whether the sensor detects the line or not. (e.g. If it's on the black line, turn right a little, if it's off the line, turn left a little).\n",
      "    *   **Why it's good:** Introduces closed-loop control and sensor feedback. Forces you to think about how to translate sensor readings into motor commands.\n",
      "    *   **Potential Challenges:** Sensor sensitivity and calibration, tuning the control loop parameters (how much to turn in response to the sensor).\n",
      "\n",
      "**Important Considerations When Choosing:**\n",
      "\n",
      "*   **Available Sensors/Hardware:** The task should align with the sensors and actuators you have available. Don't choose a task that requires a sensor you don't have and can't easily obtain.\n",
      "*   **Your Programming Experience:** Choose a task that you are confident you can program. Start with something simple and gradually increase the complexity.\n",
      "*   **Your Robot's Capabilities:** The task should be within the physical capabilities of your robot. Don't ask it to climb stairs if it's a wheeled robot.\n",
      "*   **Iteration and Testing:** Be prepared to iterate and test your code. Robotics is rarely perfect on the first try.\n",
      "\n",
      "**Recommendation for a truly first task:** Start with **\"Move in a Straight Line.\"** It's the fundamental building block for many other tasks. Once you have that working reliably, then move on to one of the other options.\n",
      "\n",
      "No matter which task you choose, break it down into smaller, manageable steps. For example, for \"Move in a Straight Line\":\n",
      "\n",
      "1.  **Get the motors moving at all.**\n",
      "2.  **Get them moving at the same speed.**\n",
      "3.  **Implement a stopping mechanism (timer-based or encoder-based).**\n",
      "4.  **Calibrate the distance.**\n",
      "\n",
      "Good luck, and have fun with Sparky! Let me know which task you choose, and I can provide more specific guidance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start a chat session\n",
    "chat = client.chats.create(model=\"gemini-2.0-flash\")\n",
    "\n",
    "# Turn 1\n",
    "response1 = chat.send_message(\"Hi, I'm building a robot named 'Sparky'.\")\n",
    "print(f\"Gemini: {response1.text}\\n\")\n",
    "\n",
    "# Turn 2 (Gemini remembers the name 'Sparky')\n",
    "response2 = chat.send_message(\"What's a good first task for my robot?\")\n",
    "print(f\"Gemini: {response2.text}\")\n",
    "\n",
    "# You can view the history at any time:\n",
    "# print(chat.get_history())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c75fce-6406-4579-8df5-37cc8765e81a",
   "metadata": {},
   "source": [
    "## Function Calling (The \"Agentic\" Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a7a5dd-c0a1-4b14-8064-b56a3b05a967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in London is 22°C and sunny.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Define a tool (a real Python function)\n",
    "def get_weather(location: str):\n",
    "    \"\"\"Returns the weather for a given location.\"\"\"\n",
    "    # In a real app, you'd call a weather API here\n",
    "    return f\"The weather in {location} is 22°C and sunny.\"\n",
    "\n",
    "# 2. Tell Gemini about the tool\n",
    "# 'automatic_function_calling' means the SDK handles the execution for you!\n",
    "chat = client.chats.create(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        tools=[get_weather]\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Ask a question that requires the tool\n",
    "response = chat.send_message(\"what is the weather of the London?\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9f73d-cc36-4f65-9825-8231a1e40d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ADK Agent Env)",
   "language": "python",
   "name": "adk_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
